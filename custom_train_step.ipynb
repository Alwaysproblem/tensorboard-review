{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('tensorboardenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bef155e77ecc852a3bc7dacbd893cd7e0992613ddee57bd2be10a2e65118a974"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split as tvsplit\n",
    "# disable logging warning and error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.config.run_functions_eagerly(True)\n",
    "# tf.config.experimental_run_functions_eagerly(True) tensorflow <= 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 100\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 1.369306 \nC 0.363144 1.369306 0.711464 1.225028 0.968246 0.968246 \nC 1.225028 0.711464 1.369306 0.363144 1.369306 0 \nC 1.369306 -0.363144 1.225028 -0.711464 0.968246 -0.968246 \nC 0.711464 -1.225028 0.363144 -1.369306 0 -1.369306 \nC -0.363144 -1.369306 -0.711464 -1.225028 -0.968246 -0.968246 \nC -1.225028 -0.711464 -1.369306 -0.363144 -1.369306 0 \nC -1.369306 0.363144 -1.225028 0.711464 -0.968246 0.968246 \nC -0.711464 1.225028 -0.363144 1.369306 0 1.369306 \nz\n\" id=\"md7ba2a2e6b\" style=\"stroke:#ff0000;\"/>\n    </defs>\n    <g clip-path=\"url(#p1c21d89b57)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"173.087791\" xlink:href=\"#md7ba2a2e6b\" y=\"139.778486\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"164.674023\" xlink:href=\"#md7ba2a2e6b\" y=\"151.341493\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"137.042003\" xlink:href=\"#md7ba2a2e6b\" y=\"180.208107\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"125.874201\" xlink:href=\"#md7ba2a2e6b\" y=\"143.76321\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"176.356459\" xlink:href=\"#md7ba2a2e6b\" y=\"156.193646\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"171.108478\" xlink:href=\"#md7ba2a2e6b\" y=\"146.070241\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"179.915701\" xlink:href=\"#md7ba2a2e6b\" y=\"151.061714\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"99.725458\" xlink:href=\"#md7ba2a2e6b\" y=\"98.884333\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"104.998463\" xlink:href=\"#md7ba2a2e6b\" y=\"132.477919\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"106.411722\" xlink:href=\"#md7ba2a2e6b\" y=\"113.829738\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"125.815351\" xlink:href=\"#md7ba2a2e6b\" y=\"132.25393\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.73604\" xlink:href=\"#md7ba2a2e6b\" y=\"92.166945\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"94.387624\" xlink:href=\"#md7ba2a2e6b\" y=\"107.933178\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"133.751464\" xlink:href=\"#md7ba2a2e6b\" y=\"125.20301\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.599442\" xlink:href=\"#md7ba2a2e6b\" y=\"130.310597\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"141.647286\" xlink:href=\"#md7ba2a2e6b\" y=\"143.762651\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"134.899633\" xlink:href=\"#md7ba2a2e6b\" y=\"141.783243\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"210.123693\" xlink:href=\"#md7ba2a2e6b\" y=\"102.034791\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.255361\" xlink:href=\"#md7ba2a2e6b\" y=\"192.678785\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.120936\" xlink:href=\"#md7ba2a2e6b\" y=\"136.273241\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"175.941589\" xlink:href=\"#md7ba2a2e6b\" y=\"193.579529\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"126.771489\" xlink:href=\"#md7ba2a2e6b\" y=\"153.933859\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"110.724253\" xlink:href=\"#md7ba2a2e6b\" y=\"154.776326\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"163.055889\" xlink:href=\"#md7ba2a2e6b\" y=\"167.643489\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.215751\" xlink:href=\"#md7ba2a2e6b\" y=\"113.166179\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"162.531421\" xlink:href=\"#md7ba2a2e6b\" y=\"111.374213\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"111.463484\" xlink:href=\"#md7ba2a2e6b\" y=\"214.286909\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"92.368109\" xlink:href=\"#md7ba2a2e6b\" y=\"158.603435\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"178.848503\" xlink:href=\"#md7ba2a2e6b\" y=\"151.46925\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"117.36604\" xlink:href=\"#md7ba2a2e6b\" y=\"140.821528\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"54.47559\" xlink:href=\"#md7ba2a2e6b\" y=\"99.308206\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"142.843788\" xlink:href=\"#md7ba2a2e6b\" y=\"111.69528\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"108.52309\" xlink:href=\"#md7ba2a2e6b\" y=\"119.391082\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"121.872439\" xlink:href=\"#md7ba2a2e6b\" y=\"135.133154\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"165.137203\" xlink:href=\"#md7ba2a2e6b\" y=\"131.392515\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"119.650194\" xlink:href=\"#md7ba2a2e6b\" y=\"137.777307\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"184.519933\" xlink:href=\"#md7ba2a2e6b\" y=\"157.61121\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"168.02229\" xlink:href=\"#md7ba2a2e6b\" y=\"105.955709\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"125.387079\" xlink:href=\"#md7ba2a2e6b\" y=\"128.840198\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"109.786314\" xlink:href=\"#md7ba2a2e6b\" y=\"162.888517\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"87.97314\" xlink:href=\"#md7ba2a2e6b\" y=\"140.05556\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"138.146212\" xlink:href=\"#md7ba2a2e6b\" y=\"114.626242\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"129.712725\" xlink:href=\"#md7ba2a2e6b\" y=\"127.921519\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"127.638847\" xlink:href=\"#md7ba2a2e6b\" y=\"135.641855\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"173.530498\" xlink:href=\"#md7ba2a2e6b\" y=\"117.901798\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"163.762918\" xlink:href=\"#md7ba2a2e6b\" y=\"150.06637\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"102.456112\" xlink:href=\"#md7ba2a2e6b\" y=\"179.705441\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"177.519629\" xlink:href=\"#md7ba2a2e6b\" y=\"128.693525\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"150.111026\" xlink:href=\"#md7ba2a2e6b\" y=\"133.849203\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"75.464732\" xlink:href=\"#md7ba2a2e6b\" y=\"148.450428\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"152.96943\" xlink:href=\"#md7ba2a2e6b\" y=\"176.787711\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"167.389753\" xlink:href=\"#md7ba2a2e6b\" y=\"153.544559\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"189.250334\" xlink:href=\"#md7ba2a2e6b\" y=\"111.320773\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"131.133207\" xlink:href=\"#md7ba2a2e6b\" y=\"143.802972\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"192.181622\" xlink:href=\"#md7ba2a2e6b\" y=\"113.662448\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"114.156333\" xlink:href=\"#md7ba2a2e6b\" y=\"139.851841\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"119.954705\" xlink:href=\"#md7ba2a2e6b\" y=\"180.007313\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"148.159633\" xlink:href=\"#md7ba2a2e6b\" y=\"165.475243\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"101.364278\" xlink:href=\"#md7ba2a2e6b\" y=\"125.871616\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"54.842579\" xlink:href=\"#md7ba2a2e6b\" y=\"116.272114\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"107.012378\" xlink:href=\"#md7ba2a2e6b\" y=\"134.74592\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"179.170313\" xlink:href=\"#md7ba2a2e6b\" y=\"141.472547\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"137.553556\" xlink:href=\"#md7ba2a2e6b\" y=\"154.589002\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"156.07284\" xlink:href=\"#md7ba2a2e6b\" y=\"124.984113\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"103.394395\" xlink:href=\"#md7ba2a2e6b\" y=\"140.7338\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.038413\" xlink:href=\"#md7ba2a2e6b\" y=\"165.579241\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"120.506971\" xlink:href=\"#md7ba2a2e6b\" y=\"152.404883\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"120.331325\" xlink:href=\"#md7ba2a2e6b\" y=\"107.44968\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"118.435607\" xlink:href=\"#md7ba2a2e6b\" y=\"118.903118\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"89.693673\" xlink:href=\"#md7ba2a2e6b\" y=\"152.464093\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"123.358888\" xlink:href=\"#md7ba2a2e6b\" y=\"168.164642\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"105.817624\" xlink:href=\"#md7ba2a2e6b\" y=\"142.786475\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"110.344708\" xlink:href=\"#md7ba2a2e6b\" y=\"127.244187\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"195.041118\" xlink:href=\"#md7ba2a2e6b\" y=\"128.431098\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"139.758788\" xlink:href=\"#md7ba2a2e6b\" y=\"165.824413\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"207.237849\" xlink:href=\"#md7ba2a2e6b\" y=\"157.330662\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"93.130194\" xlink:href=\"#md7ba2a2e6b\" y=\"143.206106\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"102.131775\" xlink:href=\"#md7ba2a2e6b\" y=\"112.378402\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"143.33178\" xlink:href=\"#md7ba2a2e6b\" y=\"152.838303\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"83.741566\" xlink:href=\"#md7ba2a2e6b\" y=\"120.88228\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"152.573233\" xlink:href=\"#md7ba2a2e6b\" y=\"133.736007\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"142.170151\" xlink:href=\"#md7ba2a2e6b\" y=\"121.204591\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"149.860231\" xlink:href=\"#md7ba2a2e6b\" y=\"142.746017\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"195.12082\" xlink:href=\"#md7ba2a2e6b\" y=\"142.302448\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"160.710771\" xlink:href=\"#md7ba2a2e6b\" y=\"159.983456\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"101.79469\" xlink:href=\"#md7ba2a2e6b\" y=\"153.641325\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"139.404173\" xlink:href=\"#md7ba2a2e6b\" y=\"132.315431\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"195.745322\" xlink:href=\"#md7ba2a2e6b\" y=\"152.362482\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"124.41829\" xlink:href=\"#md7ba2a2e6b\" y=\"137.036772\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"104.98297\" xlink:href=\"#md7ba2a2e6b\" y=\"103.799152\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"69.787678\" xlink:href=\"#md7ba2a2e6b\" y=\"106.915192\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"133.178364\" xlink:href=\"#md7ba2a2e6b\" y=\"145.713591\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"116.848307\" xlink:href=\"#md7ba2a2e6b\" y=\"152.322796\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"152.473594\" xlink:href=\"#md7ba2a2e6b\" y=\"127.131517\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"134.992138\" xlink:href=\"#md7ba2a2e6b\" y=\"151.810481\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"83.032368\" xlink:href=\"#md7ba2a2e6b\" y=\"129.242197\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"109.550421\" xlink:href=\"#md7ba2a2e6b\" y=\"82.456063\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"134.642101\" xlink:href=\"#md7ba2a2e6b\" y=\"128.996115\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"123.601594\" xlink:href=\"#md7ba2a2e6b\" y=\"148.342683\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"45.77643\" xlink:href=\"#md7ba2a2e6b\" y=\"144.967176\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <defs>\n     <path d=\"M 0 1.369306 \nC 0.363144 1.369306 0.711464 1.225028 0.968246 0.968246 \nC 1.225028 0.711464 1.369306 0.363144 1.369306 0 \nC 1.369306 -0.363144 1.225028 -0.711464 0.968246 -0.968246 \nC 0.711464 -1.225028 0.363144 -1.369306 0 -1.369306 \nC -0.363144 -1.369306 -0.711464 -1.225028 -0.968246 -0.968246 \nC -1.225028 -0.711464 -1.369306 -0.363144 -1.369306 0 \nC -1.369306 0.363144 -1.225028 0.711464 -0.968246 0.968246 \nC -0.711464 1.225028 -0.363144 1.369306 0 1.369306 \nz\n\" id=\"mb4198182b7\" style=\"stroke:#008000;\"/>\n    </defs>\n    <g clip-path=\"url(#p1c21d89b57)\">\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"190.276285\" xlink:href=\"#mb4198182b7\" y=\"37.528156\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"226.623125\" xlink:href=\"#mb4198182b7\" y=\"46.612662\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"239.886228\" xlink:href=\"#mb4198182b7\" y=\"34.768291\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"201.496987\" xlink:href=\"#mb4198182b7\" y=\"53.624817\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"284.848992\" xlink:href=\"#mb4198182b7\" y=\"57.737629\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"179.582072\" xlink:href=\"#mb4198182b7\" y=\"77.210503\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"221.113405\" xlink:href=\"#mb4198182b7\" y=\"79.560136\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"167.87018\" xlink:href=\"#mb4198182b7\" y=\"46.040247\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"239.614368\" xlink:href=\"#mb4198182b7\" y=\"34.424596\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"153.457365\" xlink:href=\"#mb4198182b7\" y=\"25.979936\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"215.858464\" xlink:href=\"#mb4198182b7\" y=\"75.435598\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"226.856468\" xlink:href=\"#mb4198182b7\" y=\"43.749325\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"195.76597\" xlink:href=\"#mb4198182b7\" y=\"70.183595\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"239.03263\" xlink:href=\"#mb4198182b7\" y=\"27.81784\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"269.763659\" xlink:href=\"#mb4198182b7\" y=\"86.825183\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"223.000462\" xlink:href=\"#mb4198182b7\" y=\"48.729527\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"287.303326\" xlink:href=\"#mb4198182b7\" y=\"72.418243\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"224.319216\" xlink:href=\"#mb4198182b7\" y=\"50.568357\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"165.500801\" xlink:href=\"#mb4198182b7\" y=\"47.853593\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"257.762081\" xlink:href=\"#mb4198182b7\" y=\"120.659851\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"250.769833\" xlink:href=\"#mb4198182b7\" y=\"45.400584\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"265.217764\" xlink:href=\"#mb4198182b7\" y=\"42.055239\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"316.850494\" xlink:href=\"#mb4198182b7\" y=\"87.525263\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"242.462617\" xlink:href=\"#mb4198182b7\" y=\"37.478441\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"238.91862\" xlink:href=\"#mb4198182b7\" y=\"42.562131\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"204.442818\" xlink:href=\"#mb4198182b7\" y=\"91.740644\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"286.692622\" xlink:href=\"#mb4198182b7\" y=\"64.836857\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"234.416451\" xlink:href=\"#mb4198182b7\" y=\"65.596271\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"189.193173\" xlink:href=\"#mb4198182b7\" y=\"37.80332\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"348.941464\" xlink:href=\"#mb4198182b7\" y=\"74.712322\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"272.575024\" xlink:href=\"#mb4198182b7\" y=\"51.160534\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"215.426284\" xlink:href=\"#mb4198182b7\" y=\"55.257688\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"179.450195\" xlink:href=\"#mb4198182b7\" y=\"32.375409\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"230.328366\" xlink:href=\"#mb4198182b7\" y=\"31.842938\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"244.667727\" xlink:href=\"#mb4198182b7\" y=\"82.296952\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"263.868893\" xlink:href=\"#mb4198182b7\" y=\"65.504083\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"246.066028\" xlink:href=\"#mb4198182b7\" y=\"40.444574\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"226.951198\" xlink:href=\"#mb4198182b7\" y=\"78.796952\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"280.240155\" xlink:href=\"#mb4198182b7\" y=\"53.7934\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"219.48859\" xlink:href=\"#mb4198182b7\" y=\"51.942997\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"208.387077\" xlink:href=\"#mb4198182b7\" y=\"63.358768\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"272.934135\" xlink:href=\"#mb4198182b7\" y=\"74.501751\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"268.248983\" xlink:href=\"#mb4198182b7\" y=\"82.592014\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"270.383542\" xlink:href=\"#mb4198182b7\" y=\"64.916354\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"235.605328\" xlink:href=\"#mb4198182b7\" y=\"29.225323\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"176.862517\" xlink:href=\"#mb4198182b7\" y=\"79.216736\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"279.066247\" xlink:href=\"#mb4198182b7\" y=\"26.544992\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"235.494818\" xlink:href=\"#mb4198182b7\" y=\"33.501613\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"202.769368\" xlink:href=\"#mb4198182b7\" y=\"36.882005\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"273.293278\" xlink:href=\"#mb4198182b7\" y=\"47.419107\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"222.123082\" xlink:href=\"#mb4198182b7\" y=\"40.830351\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"268.611526\" xlink:href=\"#mb4198182b7\" y=\"70.524905\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"225.261685\" xlink:href=\"#mb4198182b7\" y=\"48.977195\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"289.485162\" xlink:href=\"#mb4198182b7\" y=\"68.847311\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"225.724622\" xlink:href=\"#mb4198182b7\" y=\"72.536513\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"169.7961\" xlink:href=\"#mb4198182b7\" y=\"60.360343\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"297.17219\" xlink:href=\"#mb4198182b7\" y=\"71.275279\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"258.473856\" xlink:href=\"#mb4198182b7\" y=\"62.648072\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"274.363544\" xlink:href=\"#mb4198182b7\" y=\"18.003351\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"203.210307\" xlink:href=\"#mb4198182b7\" y=\"82.197356\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"251.997935\" xlink:href=\"#mb4198182b7\" y=\"46.685818\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"268.237388\" xlink:href=\"#mb4198182b7\" y=\"34.879009\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"293.340641\" xlink:href=\"#mb4198182b7\" y=\"59.659288\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"243.00927\" xlink:href=\"#mb4198182b7\" y=\"88.988803\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"240.78193\" xlink:href=\"#mb4198182b7\" y=\"93.800601\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"243.642325\" xlink:href=\"#mb4198182b7\" y=\"41.737951\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"327.314764\" xlink:href=\"#mb4198182b7\" y=\"26.017674\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"291.023814\" xlink:href=\"#mb4198182b7\" y=\"42.124476\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"216.397818\" xlink:href=\"#mb4198182b7\" y=\"33.171755\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"333.389575\" xlink:href=\"#mb4198182b7\" y=\"75.386579\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"230.319853\" xlink:href=\"#mb4198182b7\" y=\"45.7685\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"251.452379\" xlink:href=\"#mb4198182b7\" y=\"55.20367\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"167.545907\" xlink:href=\"#mb4198182b7\" y=\"41.868602\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"257.291705\" xlink:href=\"#mb4198182b7\" y=\"23.087239\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"191.230361\" xlink:href=\"#mb4198182b7\" y=\"57.587932\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"241.257282\" xlink:href=\"#mb4198182b7\" y=\"73.84748\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"190.013122\" xlink:href=\"#mb4198182b7\" y=\"70.657167\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"186.45641\" xlink:href=\"#mb4198182b7\" y=\"26.542478\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"260.607103\" xlink:href=\"#mb4198182b7\" y=\"73.388961\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"242.271317\" xlink:href=\"#mb4198182b7\" y=\"36.035994\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"150.456251\" xlink:href=\"#mb4198182b7\" y=\"80.429012\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"271.633449\" xlink:href=\"#mb4198182b7\" y=\"67.459313\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"259.76677\" xlink:href=\"#mb4198182b7\" y=\"75.432211\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"165.931051\" xlink:href=\"#mb4198182b7\" y=\"26.766164\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"289.713799\" xlink:href=\"#mb4198182b7\" y=\"84.422032\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"243.428579\" xlink:href=\"#mb4198182b7\" y=\"80.19289\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"239.158483\" xlink:href=\"#mb4198182b7\" y=\"41.61057\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"262.667773\" xlink:href=\"#mb4198182b7\" y=\"37.161085\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"242.147694\" xlink:href=\"#mb4198182b7\" y=\"36.498741\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"230.2855\" xlink:href=\"#mb4198182b7\" y=\"57.942123\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"284.191295\" xlink:href=\"#mb4198182b7\" y=\"43.145438\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"278.91845\" xlink:href=\"#mb4198182b7\" y=\"59.838709\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"233.375997\" xlink:href=\"#mb4198182b7\" y=\"51.957486\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"262.771253\" xlink:href=\"#mb4198182b7\" y=\"87.647828\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"277.035595\" xlink:href=\"#mb4198182b7\" y=\"42.89139\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"194.088957\" xlink:href=\"#mb4198182b7\" y=\"52.251257\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"226.325207\" xlink:href=\"#mb4198182b7\" y=\"37.804265\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"160.106915\" xlink:href=\"#mb4198182b7\" y=\"25.782487\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"217.640213\" xlink:href=\"#mb4198182b7\" y=\"68.979881\"/>\n     <use style=\"fill:#008000;stroke:#008000;\" x=\"228.560677\" xlink:href=\"#mb4198182b7\" y=\"91.547213\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"ma05882076e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"74.743064\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.791501 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.382651\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(122.431089 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.022239\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.5 -->\n      <g transform=\"translate(178.070677 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.661827\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(233.710264 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"297.301415\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2.5 -->\n      <g transform=\"translate(289.349852 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.941002\" xlink:href=\"#ma05882076e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(344.98944 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma50238c1f5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"209.106215\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 212.905433)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"171.832525\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 175.631744)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"134.558836\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 138.358054)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"97.285146\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 101.084365)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"60.011457\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 63.810675)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#ma50238c1f5\" y=\"22.737767\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.5 -->\n      <g transform=\"translate(7.2 26.536986)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1c21d89b57\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "meana = np.array([1, 1])\n",
    "cova = np.array([[0.1, 0],[0, 0.1]])\n",
    "\n",
    "meanb = np.array([2, 2])\n",
    "covb = np.array([[0.1, 0],[0, 0.1]])\n",
    "\n",
    "x_red = np.random.multivariate_normal(mean=meana, cov = cova, size=sample_n)\n",
    "x_green = np.random.multivariate_normal(mean=meanb, cov = covb, size=sample_n)\n",
    "\n",
    "y_red = np.array([1] * sample_n)\n",
    "y_green = np.array([0] * sample_n)\n",
    "\n",
    "plt.scatter(x_red[:, 0], x_red[:, 1], c = 'red' , marker='.', s = 30)\n",
    "plt.scatter(x_green[:, 0], x_green[:, 1], c = 'green', marker='.', s = 30)\n",
    "# plt.show()\n",
    "\n",
    "X = np.concatenate([x_red, x_green]).astype(np.float32)\n",
    "y = np.concatenate([y_red, y_green]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tvsplit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(tf.keras.models.Model):\n",
    "    def __init__(self, input_size=2, hidden_size = 5, output_size=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.inputs_ = tf.keras.Input(shape=(input_size,), dtype=tf.float32, name = \"Inputs\")\n",
    "        self._set_input_layer(self.inputs_)\n",
    "        self.dense = layers.Dense(hidden_size, name = \"linear\")\n",
    "        self.outlayer = layers.Dense(output_size, \n",
    "                        activation = 'sigmoid', name = \"out_layer\")\n",
    "        # self.inputs = tf.nest.map_structure()\n",
    "        \n",
    "        self.build()\n",
    "\n",
    "    def _set_input_layer(self, inputs):\n",
    "        \"\"\"add inputLayer to model and display InputLayers in model.summary()\n",
    "\n",
    "        Args:\n",
    "            inputs ([dict]): the result from `tf.keras.Input`\n",
    "        \"\"\"\n",
    "        if isinstance(inputs, dict):\n",
    "            self.inputs_layer = {n: tf.keras.layers.InputLayer(input_tensor=i, name=n) \n",
    "                                    for n, i in inputs.items()}\n",
    "        elif isinstance(inputs, (list, tuple)):\n",
    "            self.inputs_layer = [tf.keras.layers.InputLayer(input_tensor=i, name=i.name) \n",
    "                                    for i in inputs]\n",
    "        elif tf.is_tensor(inputs):\n",
    "            self.inputs_layer = tf.keras.layers.InputLayer(input_tensor=inputs, name=inputs.name)\n",
    "    \n",
    "    def build(self):\n",
    "        super(Logistic, self).build(self.inputs_.shape if tf.is_tensor(self.inputs_) else self.inputs_)\n",
    "        # super(Logistic, self).build((None, 2))\n",
    "        _ = self.call(self.inputs_)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, X):\n",
    "        X = self.dense(X)\n",
    "        Y = self.outlayer(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"logistic\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nInputs (InputLayer)          [(None, 2)]               0         \n_________________________________________________________________\nlinear (Dense)               (None, 5)                 15        \n_________________________________________________________________\nout_layer (Dense)            (None, 1)                 6         \n=================================================================\nTotal params: 21\nTrainable params: 21\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Logistic()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# logdir = \"logs\" + os.path.sep + \"standard\" + os.path.sep + datetime.now().strftime(\"\"\"%Y%m%d-%H%M%S\"\"\")\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.8427 - accuracy: 0.4716 - val_loss: 0.7132 - val_accuracy: 0.5800\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.8082 - accuracy: 0.4833 - val_loss: 0.7000 - val_accuracy: 0.5800\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8034 - accuracy: 0.4781 - val_loss: 0.6876 - val_accuracy: 0.5800\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7681 - accuracy: 0.4946 - val_loss: 0.6759 - val_accuracy: 0.5800\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7849 - accuracy: 0.4685 - val_loss: 0.6649 - val_accuracy: 0.5800\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.7585 - accuracy: 0.4833 - val_loss: 0.6548 - val_accuracy: 0.5800\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7623 - accuracy: 0.4659 - val_loss: 0.6454 - val_accuracy: 0.5800\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7453 - accuracy: 0.4724 - val_loss: 0.6366 - val_accuracy: 0.5800\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6928 - accuracy: 0.5041 - val_loss: 0.6287 - val_accuracy: 0.5800\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7186 - accuracy: 0.4738 - val_loss: 0.6211 - val_accuracy: 0.5800\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6695 - accuracy: 0.5059 - val_loss: 0.6142 - val_accuracy: 0.5800\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6759 - accuracy: 0.4946 - val_loss: 0.6078 - val_accuracy: 0.5800\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7005 - accuracy: 0.4655 - val_loss: 0.6018 - val_accuracy: 0.5800\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6978 - accuracy: 0.4599 - val_loss: 0.5964 - val_accuracy: 0.5800\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6730 - accuracy: 0.4807 - val_loss: 0.5916 - val_accuracy: 0.5800\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6369 - accuracy: 0.5024 - val_loss: 0.5875 - val_accuracy: 0.5800\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6759 - accuracy: 0.4525 - val_loss: 0.5836 - val_accuracy: 0.5800\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6341 - accuracy: 0.4911 - val_loss: 0.5802 - val_accuracy: 0.5800\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6565 - accuracy: 0.4625 - val_loss: 0.5771 - val_accuracy: 0.5800\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6107 - accuracy: 0.5115 - val_loss: 0.5745 - val_accuracy: 0.5800\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6121 - accuracy: 0.5089 - val_loss: 0.5721 - val_accuracy: 0.5800\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6295 - accuracy: 0.4694 - val_loss: 0.5700 - val_accuracy: 0.5800\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6250 - accuracy: 0.4790 - val_loss: 0.5682 - val_accuracy: 0.5800\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6255 - accuracy: 0.4620 - val_loss: 0.5667 - val_accuracy: 0.5800\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5904 - accuracy: 0.5241 - val_loss: 0.5653 - val_accuracy: 0.5800\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6195 - accuracy: 0.4699 - val_loss: 0.5641 - val_accuracy: 0.5800\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6175 - accuracy: 0.4712 - val_loss: 0.5631 - val_accuracy: 0.5800\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5859 - accuracy: 0.5098 - val_loss: 0.5621 - val_accuracy: 0.5800\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6093 - accuracy: 0.4699 - val_loss: 0.5614 - val_accuracy: 0.5800\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5944 - accuracy: 0.5051 - val_loss: 0.5606 - val_accuracy: 0.5800\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5791 - accuracy: 0.5268 - val_loss: 0.5599 - val_accuracy: 0.5800\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5943 - accuracy: 0.4856 - val_loss: 0.5593 - val_accuracy: 0.5800\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5839 - accuracy: 0.5083 - val_loss: 0.5586 - val_accuracy: 0.5800\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5895 - accuracy: 0.5048 - val_loss: 0.5580 - val_accuracy: 0.5800\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5787 - accuracy: 0.5152 - val_loss: 0.5572 - val_accuracy: 0.6000\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5932 - accuracy: 0.5114 - val_loss: 0.5565 - val_accuracy: 0.6000\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5954 - accuracy: 0.4940 - val_loss: 0.5557 - val_accuracy: 0.6000\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5891 - accuracy: 0.5271 - val_loss: 0.5548 - val_accuracy: 0.6200\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5768 - accuracy: 0.5511 - val_loss: 0.5537 - val_accuracy: 0.6400\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5825 - accuracy: 0.5746 - val_loss: 0.5527 - val_accuracy: 0.6400\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5860 - accuracy: 0.5377 - val_loss: 0.5518 - val_accuracy: 0.6400\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5820 - accuracy: 0.5552 - val_loss: 0.5508 - val_accuracy: 0.6400\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5719 - accuracy: 0.5830 - val_loss: 0.5495 - val_accuracy: 0.6400\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5915 - accuracy: 0.5366 - val_loss: 0.5486 - val_accuracy: 0.6600\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5642 - accuracy: 0.6006 - val_loss: 0.5472 - val_accuracy: 0.6600\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5791 - accuracy: 0.5798 - val_loss: 0.5460 - val_accuracy: 0.6600\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5730 - accuracy: 0.6072 - val_loss: 0.5445 - val_accuracy: 0.6600\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5883 - accuracy: 0.5577 - val_loss: 0.5432 - val_accuracy: 0.6600\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5909 - accuracy: 0.5874 - val_loss: 0.5418 - val_accuracy: 0.6600\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5668 - accuracy: 0.6309 - val_loss: 0.5400 - val_accuracy: 0.6600\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5792 - accuracy: 0.6015 - val_loss: 0.5382 - val_accuracy: 0.6600\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5525 - accuracy: 0.7009 - val_loss: 0.5362 - val_accuracy: 0.6800\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5698 - accuracy: 0.6436 - val_loss: 0.5347 - val_accuracy: 0.6800\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5671 - accuracy: 0.6719 - val_loss: 0.5330 - val_accuracy: 0.6800\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5776 - accuracy: 0.6212 - val_loss: 0.5312 - val_accuracy: 0.6800\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5627 - accuracy: 0.6673 - val_loss: 0.5294 - val_accuracy: 0.6800\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5398 - accuracy: 0.7250 - val_loss: 0.5272 - val_accuracy: 0.6800\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5577 - accuracy: 0.6994 - val_loss: 0.5257 - val_accuracy: 0.7000\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5561 - accuracy: 0.6979 - val_loss: 0.5240 - val_accuracy: 0.7000\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5484 - accuracy: 0.7079 - val_loss: 0.5224 - val_accuracy: 0.7000\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5571 - accuracy: 0.6823 - val_loss: 0.5208 - val_accuracy: 0.7200\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5401 - accuracy: 0.7610 - val_loss: 0.5187 - val_accuracy: 0.7200\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5551 - accuracy: 0.7567 - val_loss: 0.5171 - val_accuracy: 0.7200\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5420 - accuracy: 0.7385 - val_loss: 0.5152 - val_accuracy: 0.7200\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7772 - val_loss: 0.5130 - val_accuracy: 0.7200\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5451 - accuracy: 0.7555 - val_loss: 0.5113 - val_accuracy: 0.7200\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5255 - accuracy: 0.7716 - val_loss: 0.5092 - val_accuracy: 0.7200\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5345 - accuracy: 0.7773 - val_loss: 0.5075 - val_accuracy: 0.7200\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5336 - accuracy: 0.7652 - val_loss: 0.5056 - val_accuracy: 0.7600\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5341 - accuracy: 0.7818 - val_loss: 0.5038 - val_accuracy: 0.7600\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5079 - accuracy: 0.8183 - val_loss: 0.5014 - val_accuracy: 0.7600\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5303 - accuracy: 0.7941 - val_loss: 0.4998 - val_accuracy: 0.7800\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5279 - accuracy: 0.7919 - val_loss: 0.4980 - val_accuracy: 0.7800\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5105 - accuracy: 0.8353 - val_loss: 0.4957 - val_accuracy: 0.7800\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5072 - accuracy: 0.8241 - val_loss: 0.4936 - val_accuracy: 0.8200\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5167 - accuracy: 0.8107 - val_loss: 0.4918 - val_accuracy: 0.8400\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5107 - accuracy: 0.8555 - val_loss: 0.4896 - val_accuracy: 0.8400\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5125 - accuracy: 0.8225 - val_loss: 0.4878 - val_accuracy: 0.8600\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4968 - accuracy: 0.8620 - val_loss: 0.4855 - val_accuracy: 0.8600\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5199 - accuracy: 0.8391 - val_loss: 0.4838 - val_accuracy: 0.8600\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5048 - accuracy: 0.8954 - val_loss: 0.4816 - val_accuracy: 0.8600\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4933 - accuracy: 0.9162 - val_loss: 0.4792 - val_accuracy: 0.8600\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5006 - accuracy: 0.8997 - val_loss: 0.4769 - val_accuracy: 0.8600\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4994 - accuracy: 0.8820 - val_loss: 0.4749 - val_accuracy: 0.8800\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4947 - accuracy: 0.8937 - val_loss: 0.4726 - val_accuracy: 0.8800\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4987 - accuracy: 0.8876 - val_loss: 0.4706 - val_accuracy: 0.8800\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4957 - accuracy: 0.9067 - val_loss: 0.4683 - val_accuracy: 0.8800\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4784 - accuracy: 0.9115 - val_loss: 0.4658 - val_accuracy: 0.8800\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4938 - accuracy: 0.8750 - val_loss: 0.4636 - val_accuracy: 0.8800\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4831 - accuracy: 0.8937 - val_loss: 0.4613 - val_accuracy: 0.8800\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4815 - accuracy: 0.8990 - val_loss: 0.4592 - val_accuracy: 0.8800\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4685 - accuracy: 0.9203 - val_loss: 0.4566 - val_accuracy: 0.9000\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4770 - accuracy: 0.8990 - val_loss: 0.4544 - val_accuracy: 0.9000\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4747 - accuracy: 0.8986 - val_loss: 0.4522 - val_accuracy: 0.9000\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4665 - accuracy: 0.9303 - val_loss: 0.4498 - val_accuracy: 0.9000\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4699 - accuracy: 0.9017 - val_loss: 0.4475 - val_accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4744 - accuracy: 0.9126 - val_loss: 0.4452 - val_accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4611 - accuracy: 0.9165 - val_loss: 0.4427 - val_accuracy: 0.9000\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4634 - accuracy: 0.8965 - val_loss: 0.4403 - val_accuracy: 0.9000\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4466 - accuracy: 0.9513 - val_loss: 0.4379 - val_accuracy: 0.9000\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4575 - accuracy: 0.9287 - val_loss: 0.4356 - val_accuracy: 0.9200\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4601 - accuracy: 0.9235 - val_loss: 0.4335 - val_accuracy: 0.9200\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4516 - accuracy: 0.9269 - val_loss: 0.4314 - val_accuracy: 0.9200\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4581 - accuracy: 0.9275 - val_loss: 0.4290 - val_accuracy: 0.9200\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4384 - accuracy: 0.9301 - val_loss: 0.4264 - val_accuracy: 0.9200\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4414 - accuracy: 0.9406 - val_loss: 0.4240 - val_accuracy: 0.9200\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4283 - accuracy: 0.9588 - val_loss: 0.4213 - val_accuracy: 0.9200\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4484 - accuracy: 0.9489 - val_loss: 0.4192 - val_accuracy: 0.9200\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4435 - accuracy: 0.9519 - val_loss: 0.4170 - val_accuracy: 0.9200\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4331 - accuracy: 0.9562 - val_loss: 0.4145 - val_accuracy: 0.9200\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4357 - accuracy: 0.9636 - val_loss: 0.4120 - val_accuracy: 0.9200\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4269 - accuracy: 0.9449 - val_loss: 0.4095 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4174 - accuracy: 0.9736 - val_loss: 0.4072 - val_accuracy: 0.9200\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4261 - accuracy: 0.9611 - val_loss: 0.4049 - val_accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4282 - accuracy: 0.9589 - val_loss: 0.4027 - val_accuracy: 0.9600\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4159 - accuracy: 0.9671 - val_loss: 0.4002 - val_accuracy: 0.9600\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4240 - accuracy: 0.9415 - val_loss: 0.3980 - val_accuracy: 0.9600\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4060 - accuracy: 0.9767 - val_loss: 0.3953 - val_accuracy: 0.9600\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4199 - accuracy: 0.9615 - val_loss: 0.3930 - val_accuracy: 0.9600\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.4093 - accuracy: 0.9572 - val_loss: 0.3906 - val_accuracy: 0.9600\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4031 - accuracy: 0.9619 - val_loss: 0.3878 - val_accuracy: 0.9600\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3902 - accuracy: 0.9697 - val_loss: 0.3851 - val_accuracy: 0.9600\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4071 - accuracy: 0.9585 - val_loss: 0.3828 - val_accuracy: 0.9600\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3993 - accuracy: 0.9715 - val_loss: 0.3804 - val_accuracy: 0.9600\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4052 - accuracy: 0.9619 - val_loss: 0.3782 - val_accuracy: 0.9600\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3836 - accuracy: 0.9550 - val_loss: 0.3755 - val_accuracy: 0.9600\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3883 - accuracy: 0.9694 - val_loss: 0.3731 - val_accuracy: 0.9600\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3987 - accuracy: 0.9442 - val_loss: 0.3705 - val_accuracy: 0.9600\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3856 - accuracy: 0.9733 - val_loss: 0.3681 - val_accuracy: 0.9600\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3793 - accuracy: 0.9746 - val_loss: 0.3657 - val_accuracy: 0.9600\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3820 - accuracy: 0.9637 - val_loss: 0.3633 - val_accuracy: 0.9600\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3794 - accuracy: 0.9585 - val_loss: 0.3610 - val_accuracy: 0.9600\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3797 - accuracy: 0.9520 - val_loss: 0.3588 - val_accuracy: 0.9600\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3629 - accuracy: 0.9685 - val_loss: 0.3564 - val_accuracy: 0.9600\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3672 - accuracy: 0.9702 - val_loss: 0.3539 - val_accuracy: 0.9600\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3637 - accuracy: 0.9650 - val_loss: 0.3514 - val_accuracy: 0.9600\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3536 - accuracy: 0.9733 - val_loss: 0.3493 - val_accuracy: 0.9800\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3613 - accuracy: 0.9546 - val_loss: 0.3472 - val_accuracy: 0.9800\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3485 - accuracy: 0.9655 - val_loss: 0.3448 - val_accuracy: 0.9800\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3434 - accuracy: 0.9789 - val_loss: 0.3424 - val_accuracy: 0.9800\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3484 - accuracy: 0.9802 - val_loss: 0.3402 - val_accuracy: 0.9800\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3381 - accuracy: 0.9663 - val_loss: 0.3379 - val_accuracy: 0.9800\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3443 - accuracy: 0.9733 - val_loss: 0.3358 - val_accuracy: 0.9800\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3421 - accuracy: 0.9702 - val_loss: 0.3336 - val_accuracy: 0.9800\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3383 - accuracy: 0.9776 - val_loss: 0.3312 - val_accuracy: 0.9800\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3339 - accuracy: 0.9637 - val_loss: 0.3289 - val_accuracy: 0.9800\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3425 - accuracy: 0.9737 - val_loss: 0.3267 - val_accuracy: 0.9800\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3360 - accuracy: 0.9572 - val_loss: 0.3241 - val_accuracy: 0.9800\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3398 - accuracy: 0.9503 - val_loss: 0.3215 - val_accuracy: 0.9800\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3274 - accuracy: 0.9720 - val_loss: 0.3190 - val_accuracy: 0.9800\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3385 - accuracy: 0.9520 - val_loss: 0.3167 - val_accuracy: 0.9800\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3197 - accuracy: 0.9746 - val_loss: 0.3142 - val_accuracy: 0.9800\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3170 - accuracy: 0.9589 - val_loss: 0.3117 - val_accuracy: 0.9800\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3129 - accuracy: 0.9646 - val_loss: 0.3096 - val_accuracy: 0.9800\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3181 - accuracy: 0.9637 - val_loss: 0.3073 - val_accuracy: 0.9800\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3145 - accuracy: 0.9615 - val_loss: 0.3052 - val_accuracy: 0.9800\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3128 - accuracy: 0.9624 - val_loss: 0.3034 - val_accuracy: 0.9800\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3203 - accuracy: 0.9550 - val_loss: 0.3012 - val_accuracy: 0.9800\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2951 - accuracy: 0.9750 - val_loss: 0.2989 - val_accuracy: 0.9800\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3100 - accuracy: 0.9655 - val_loss: 0.2968 - val_accuracy: 0.9800\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3037 - accuracy: 0.9715 - val_loss: 0.2948 - val_accuracy: 0.9800\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2964 - accuracy: 0.9776 - val_loss: 0.2925 - val_accuracy: 0.9800\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3008 - accuracy: 0.9650 - val_loss: 0.2904 - val_accuracy: 0.9800\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3101 - accuracy: 0.9520 - val_loss: 0.2884 - val_accuracy: 0.9800\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3017 - accuracy: 0.9607 - val_loss: 0.2863 - val_accuracy: 0.9800\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2830 - accuracy: 0.9715 - val_loss: 0.2842 - val_accuracy: 0.9800\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.2814 - accuracy: 0.9689 - val_loss: 0.2821 - val_accuracy: 0.9800\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2852 - accuracy: 0.9698 - val_loss: 0.2800 - val_accuracy: 0.9800\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2955 - accuracy: 0.9585 - val_loss: 0.2782 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2761 - accuracy: 0.9742 - val_loss: 0.2761 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2808 - accuracy: 0.9781 - val_loss: 0.2741 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2799 - accuracy: 0.9777 - val_loss: 0.2722 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2772 - accuracy: 0.9659 - val_loss: 0.2702 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2713 - accuracy: 0.9703 - val_loss: 0.2679 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2720 - accuracy: 0.9790 - val_loss: 0.2660 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2710 - accuracy: 0.9659 - val_loss: 0.2642 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2771 - accuracy: 0.9738 - val_loss: 0.2624 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2675 - accuracy: 0.9847 - val_loss: 0.2605 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2680 - accuracy: 0.9716 - val_loss: 0.2586 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2579 - accuracy: 0.9807 - val_loss: 0.2565 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2551 - accuracy: 0.9864 - val_loss: 0.2544 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2695 - accuracy: 0.9608 - val_loss: 0.2526 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2605 - accuracy: 0.9716 - val_loss: 0.2508 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.2557 - accuracy: 0.9768 - val_loss: 0.2489 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2592 - accuracy: 0.9825 - val_loss: 0.2470 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2369 - accuracy: 0.9903 - val_loss: 0.2451 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2432 - accuracy: 0.9847 - val_loss: 0.2436 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2356 - accuracy: 0.9886 - val_loss: 0.2417 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2531 - accuracy: 0.9869 - val_loss: 0.2399 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2389 - accuracy: 0.9847 - val_loss: 0.2380 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2505 - accuracy: 0.9739 - val_loss: 0.2363 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2371 - accuracy: 0.9930 - val_loss: 0.2344 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2391 - accuracy: 0.9817 - val_loss: 0.2326 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2390 - accuracy: 0.9895 - val_loss: 0.2309 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2350 - accuracy: 0.9847 - val_loss: 0.2292 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2273 - accuracy: 0.9925 - val_loss: 0.2275 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2417 - accuracy: 0.9834 - val_loss: 0.2259 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2289 - accuracy: 0.9739 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2241 - accuracy: 0.9912 - val_loss: 0.2226 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2205 - accuracy: 0.9925 - val_loss: 0.2209 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf73f1d050>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "epochs = 200\n",
    "model.fit(x=X_train, y=y_train, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.2209271>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "loss = model.compiled_loss._loss_metric\n",
    "loss.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Variable <tf.Variable 'linear/kernel:0' shape=(2, 5) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9cc554ae9c26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# weights = [w for w in model.trainable_weights if 'dense' in w.name and 'bias' in w.name]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorboardenv/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    721\u001b[0m                            \u001b[0;34m\"gradient defined (i.e. are differentiable). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                            \u001b[0;34m\"Common ops without gradient: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                            \"K.argmax, K.round, K.eval.\".format(param))\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable <tf.Variable 'linear/kernel:0' shape=(2, 5) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "loss = model.compiled_loss._loss_metric\n",
    "# weights = [w for w in model.trainable_weights if 'dense' in w.name and 'bias' in w.name]\n",
    "opt = model.optimizer\n",
    "opt.get_gradients(loss.result(), model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}