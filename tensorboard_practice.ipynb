{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb=keras.datasets.imdb\n",
    "(train_x, train_y), (test_x, text_y)=keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_x), len(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len: ',len(train_x[0]), len(train_x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index  = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {k:(v+3) for k, v in word_index.items()}\n",
    "word2id['<PAD>'] = 0\n",
    "word2id['<START>'] = 1\n",
    "word2id['<UNK>'] = 2\n",
    "word2id['<UNUSED>'] = 3\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "def get_words(sent_ids):\n",
    "    return ' '.join([id2word.get(i, '?') for i in sent_ids])\n",
    "\n",
    "sent = get_words(train_x[0])\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./logs/text_classify/word.tsv','w',encoding='utf-8') as f:\n",
    "    for i in range(len(word2id)):\n",
    "        f.write('{}\\n'.format(id2word[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句子末尾padding\n",
    "train_x = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_x, value=word2id['<PAD>'],\n",
    "    padding='post', maxlen=256\n",
    ")\n",
    "test_x = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_x, value=word2id['<PAD>'],\n",
    "    padding='post', maxlen=256\n",
    ")\n",
    "print(train_x[0])\n",
    "print('len: ',len(train_x[0]), len(train_x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "vocab_size = 10000\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 16,name='embed'))\n",
    "model.add(layers.GlobalAveragePooling1D(name='pool'))\n",
    "model.add(layers.Dense(16, activation='relu',name='relu_layer'))\n",
    "model.add(layers.Dense(1, activation='sigmoid',name='output_layer'))\n",
    "model.summary()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_embed = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_embed.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_path = './model_save/text_classify/model.ckpt'\n",
    "callback = [\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='./logs/text_classify',histogram_freq=5000,\n",
    "            write_graph=True, write_images=False,update_freq='epoch',\n",
    "            embeddings_freq=1,\n",
    "            embeddings_metadata ={layer_embed.name:'word.tsv'}),\n",
    "            tf.keras.callbacks.ModelCheckpoint(check_path,save_weights_only=True,verbose=1,save_freq=10000)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_x[:10000]\n",
    "x_train = train_x[10000:]\n",
    "\n",
    "y_val = train_y[:10000]\n",
    "y_train = train_y[10000:]\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "                   epochs=5, batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1,callbacks = callback)\n",
    "\n",
    "result = model.evaluate(test_x, text_y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tf2cpu': conda)",
   "language": "python",
   "name": "python37464bittf2cpucondac236f1612a774c1b9ef8eec7483a7290"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}